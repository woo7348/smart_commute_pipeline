"""
fetch_weather.py
-----------------
ê¸°ìƒì²­ ASOS(ì¢…ê´€ê¸°ìƒê´€ì¸¡) ì¼ë³„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
NiFi ìë™í™”ë¥¼ ìœ„í•´ ì•„ë˜ ì›ì¹™ìœ¼ë¡œ ë¦¬íŒ©í† ë§ë¨:

1. ëª¨ë“  Raw íŒŒì¼ì„ í”„ë¡œì íŠ¸ ì ˆëŒ€ê²½ë¡œ ê¸°ì¤€ì˜ êµ¬ì¡°ì  í´ë”ì— ì €ì¥
   data/raw/weather/YYYY/MM/

2. ì‚¬ìš©ì ì…ë ¥ ì œê±° (cron + NiFi ìë™í™” í™˜ê²½ì—ì„œëŠ” input ì‚¬ìš© ë¶ˆê°€)

3. Airflow â†’ NiFi ì „í™˜ì„ ìœ„í•œ ë¶„ë¦¬ êµ¬ì¡°
   - Python: Extract(ë°ì´í„° ìˆ˜ì§‘)ë§Œ ë‹´ë‹¹
   - NiFi: Transform + Load ë‹´ë‹¹

4. ì£¼ ë‹¨ìœ„ chunk ìš”ì²­ í›„, ì›” ë‹¨ìœ„ full íŒŒì¼ ìƒì„±
   â†’ NiFiëŠ” full íŒŒì¼ë§Œ ì½ìœ¼ë©´ ë¨

Author : MinWoo Kang
Project: Smart Commute Pipeline
"""

import os
import json
import time
import requests
from dotenv import load_dotenv
from datetime import datetime, timedelta

# --------------------------------------------------------------------
# ğŸŒ í™˜ê²½ ë³€ìˆ˜ ë° ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------
load_dotenv()

SERVICE_KEY = os.getenv("WEATHER_API_KEY")
if not SERVICE_KEY:
    raise ValueError("âŒ WEATHER_API_KEY not found in .env file")

BASE_URL = "http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList"

# í”„ë¡œì íŠ¸ ì ˆëŒ€ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# NiFiê°€ ì½ì„ Raw ë°ì´í„° ì €ì¥ ê²½ë¡œ
RAW_WEATHER_DIR = os.path.join(BASE_DIR, "../data/raw/weather")


# --------------------------------------------------------------------
# ğŸ§© ê³µí†µ í•¨ìˆ˜: JSON ì €ì¥ (NiFi Friendly Directory)
# --------------------------------------------------------------------
def save_json(year, month, stn_id, filename, data):
    """
    JSON íŒŒì¼ì„ ì•„ë˜ êµ¬ì¡°ë¡œ ì €ì¥:
    data/raw/weather/YYYY/MM/filename.json
    """
    year_dir = os.path.join(RAW_WEATHER_DIR, str(year))
    month_dir = os.path.join(year_dir, f"{month:02d}")

    os.makedirs(month_dir, exist_ok=True)

    filepath = os.path.join(month_dir, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ Saved â†’ {filepath}")
    return filepath


# --------------------------------------------------------------------
# ğŸ” ì•ˆì „í•œ ìš”ì²­ í•¨ìˆ˜ (ì¬ì‹œë„)
# --------------------------------------------------------------------
def safe_request(params, max_retries=3, delay=5):
    """API ìš”ì²­ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„"""
    for attempt in range(1, max_retries + 1):
        try:
            response = requests.get(BASE_URL, params=params, timeout=(5, 60))
            response.raise_for_status()
            return response
        except Exception as e:
            print(f"âš ï¸ Attempt {attempt}/{max_retries} failed: {e}")
            time.sleep(delay)

    print("âŒ All retry attempts failed.")
    return None


# --------------------------------------------------------------------
# ğŸ“¥ ë‹¨ì¼ ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘ (ì£¼ ë‹¨ìœ„)
# --------------------------------------------------------------------
def fetch_asos_daily(start_date, end_date, year, month, stn_id="108"):
    """
    ì£¼ ë‹¨ìœ„ ë°ì´í„° ìˆ˜ì§‘ í›„ raw í´ë”ì— ì €ì¥.
    """
    filename = f"asos_daily_{stn_id}_{start_date}_{end_date}.json"

    params = {
        "serviceKey": SERVICE_KEY,
        "dataCd": "ASOS",
        "dateCd": "DAY",
        "startDt": start_date,
        "endDt": end_date,
        "stnIds": stn_id,
        "dataType": "JSON",
        "numOfRows": 100,
        "pageNo": 1,
    }

    print(f"ğŸ“¡ Requesting ASOS Daily ({start_date} ~ {end_date})")

    response = safe_request(params)
    if not response:
        return None

    data = response.json()
    items = data.get("response", {}).get("body", {}).get("items", {}).get("item", [])

    if not items:
        print("âš ï¸ No data returned.")
        return None

    # ì €ì¥
    save_json(year, month, stn_id, filename, items)
    return items


# --------------------------------------------------------------------
# ğŸ“… ì „ì²´ ì›” ë°ì´í„°ë¥¼ ì£¼ ë‹¨ìœ„ë¡œ fetch í›„ ë³‘í•©
# --------------------------------------------------------------------
def fetch_asos_month_chunked(year, month, stn_id="108"):
    """
    1. í•œ ë‹¬ ë°ì´í„°ë¥¼ 7ì¼ ë‹¨ìœ„ë¡œ ë¶„í•  ìš”ì²­
    2. ì£¼ê°„ íŒŒì¼ ì €ì¥
    3. ì›” ë‹¨ìœ„ full JSON ìƒì„±
    4. ì¤‘ê°„ ì£¼ê°„ íŒŒì¼ ì‚­ì œ
    """
    print(f"ğŸ“… Fetching ASOS Monthly â†’ {year}-{month:02d}")

    start = datetime(year, month, 1)
    end = (start + timedelta(days=31)).replace(day=1) - timedelta(days=1)

    all_items = []
    weekly_files = []
    delta = timedelta(days=7)

    while start <= end:
        chunk_start = start.strftime("%Y%m%d")
        chunk_end = min(start + delta - timedelta(days=1), end).strftime("%Y%m%d")

        items = fetch_asos_daily(chunk_start, chunk_end, year, month, stn_id)

        if items:
            all_items.extend(items)
            weekly_files.append(
                os.path.join(
                    RAW_WEATHER_DIR, f"{year}/{month:02d}/asos_daily_{stn_id}_{chunk_start}_{chunk_end}.json"
                )
            )

        start += delta
        time.sleep(1)

    # ì›” ë‹¨ìœ„ full íŒŒì¼ ì €ì¥
    full_filename = f"asos_daily_{stn_id}_{year}{month:02d}_full.json"
    save_json(year, month, stn_id, full_filename, all_items)

    # ì¤‘ê°„ weekly íŒŒì¼ ì‚­ì œ
    for path in weekly_files:
        if os.path.exists(path):
            os.remove(path)
            print(f"ğŸ—‘ Removed weekly â†’ {path}")

    print(f"âœ… Completed Monthly Fetch: {year}-{month:02d}")


# --------------------------------------------------------------------
# ğŸš€ ì‹¤í–‰ë¶€ (í¬ë¡ ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥)
# --------------------------------------------------------------------
if __name__ == "__main__":
    stn_id = "108"
    start_year = 2025
    start_month = 4

    today = datetime.now()
    current_year = today.year
    current_month = today.month

    # ê³¼ê±° ~ ì§€ë‚œë‹¬ê¹Œì§€ ìë™ í™•ì¸ ë° ëˆ„ë½ë¶„ ìˆ˜ì§‘
    for year in range(start_year, current_year + 1):
        # í˜„ì¬ ì—°ë„ëŠ” ì§€ë‚œë‹¬ê¹Œì§€ë§Œ
        max_month = 12 if year < current_year else current_month - 1

        for month in range(start_month, max_month + 1):
            # ì›” ë‹¨ìœ„ Full íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            expected_full_file = os.path.join(
                RAW_WEATHER_DIR,
                f"{year}/{month:02d}/asos_daily_{stn_id}_{year}{month:02d}_full.json"
            )

            if not os.path.exists(expected_full_file):
                print(f"ğŸ“¡ Missing month â†’ Fetching {year}-{month:02d}")
                fetch_asos_month_chunked(year, month, stn_id)
            else:
                print(f"âœ… Exists: {expected_full_file}")

    print("ğŸ‰ Weather Extract Completed Successfully")
