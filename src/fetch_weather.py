"""
fetch_weather.py
-----------------
ê¸°ìƒì²­ ASOS(ì¢…ê´€ê¸°ìƒê´€ì¸¡) ì¼ë³„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
- ë§¤ë‹¬ 1ì¼ ì˜¤í›„ 2ì‹œì— ìë™ í˜¸ì¶œë˜ì–´ ì§€ë‚œë‹¬ 1ì¼~ë§ì¼ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´.
- ê° ì£¼ê°„ ë°ì´í„°ë¥¼ raw í´ë”ì— ê°œë³„ JSONìœ¼ë¡œ ì €ì¥í•œ ë’¤, ìµœì¢…ì ìœ¼ë¡œ í•œ ë‹¬ì¹˜ ë°ì´í„°ë¥¼ ë³‘í•©.

Author : MinWoo Kang
Project: Smart Commute Pipeline
"""

import os
import requests
import json
import time
from dotenv import load_dotenv
from datetime import datetime, timedelta

# --------------------------------------------------------------------
# âœ… í™˜ê²½ ë³€ìˆ˜ ë° API ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------
load_dotenv()
SERVICE_KEY = os.getenv("WEATHER_API_KEY")
if not SERVICE_KEY:
    raise ValueError("âŒ WEATHER_API_KEY not found in .env file")

BASE_URL = "http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList"

# --------------------------------------------------------------------
# âœ… 1ï¸âƒ£ ì•ˆì „í•œ ìš”ì²­ í•¨ìˆ˜ (ì¬ì‹œë„ + ì§€ì—° í¬í•¨)
# --------------------------------------------------------------------
def safe_request(params, max_retries=3, delay=5):
    """ìš”ì²­ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ + ì§€ì—°"""
    for attempt in range(1, max_retries + 1):
        try:
            response = requests.get(BASE_URL, params=params, timeout=(5, 60))
            response.raise_for_status()
            return response
        except requests.exceptions.Timeout:
            print(f"â³ Timeout on attempt {attempt}/{max_retries}. Retrying in {delay}s...")
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ Request failed on attempt {attempt}/{max_retries}: {e}")
        time.sleep(delay)
    print("âŒ All retry attempts failed.")
    return None

# --------------------------------------------------------------------
# âœ… 2ï¸âƒ£ ë‹¨ì¼ êµ¬ê°„ ë°ì´í„° ìš”ì²­ í•¨ìˆ˜
# --------------------------------------------------------------------
def fetch_asos_daily(start_date, end_date, stn_id="108"):
    """ê¸°ìƒì²­ ASOS ì¼ë³„ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ (ì£¼ê°„ ë‹¨ìœ„)"""
    filename = f"asos_daily_{stn_id}_{start_date}_{end_date}.json"
    params = {
        "serviceKey": SERVICE_KEY,
        "dataCd": "ASOS",
        "dateCd": "DAY",
        "startDt": start_date,
        "endDt": end_date,
        "stnIds": stn_id,
        "dataType": "JSON",
        "numOfRows": 100,
        "pageNo": 1,
    }

    print(f"ğŸ“¡ Requesting ASOS Daily data ({start_date} ~ {end_date}, stn={stn_id})")
    response = safe_request(params)

    if not response:
        print(f"âŒ Skipping period ({start_date} ~ {end_date}) due to repeated failures.")
        return None

    data = response.json()
    items = data.get("response", {}).get("body", {}).get("items", {}).get("item", [])

    if not items:
        print("âš ï¸ No data found for given date range or station ID.")
        return None

    os.makedirs("raw", exist_ok=True)
    filepath = f"raw/{filename}"

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=2)

    print(f"âœ… Saved ASOS daily data â†’ {filepath}")
    return items

# --------------------------------------------------------------------
# âœ… 3ï¸âƒ£ ì›” ë‹¨ìœ„ ë°ì´í„° ë³‘í•© í•¨ìˆ˜ (ì£¼ ë‹¨ìœ„ ë¶„í•  í˜¸ì¶œ)
# --------------------------------------------------------------------
def fetch_asos_month_chunked(year, month, stn_id="108"):
    """í•œ ë‹¬ ë°ì´í„°ë¥¼ ì£¼ ë‹¨ìœ„ë¡œ ë¶„í•  ìš”ì²­ í›„ ë³‘í•© ì €ì¥ + ì¤‘ê°„ íŒŒì¼ ìë™ ì‚­ì œ"""
    start = datetime(year, month, 1)
    end = (start + timedelta(days=31)).replace(day=1) - timedelta(days=1)

    all_items = []             # ì „ì²´ ë°ì´í„°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    saved_files = []           # âœ… ì—¬ê¸°ì„œ ë°˜ë“œì‹œ ì´ˆê¸°í™” (ì¤‘ê°„íŒŒì¼ ê²½ë¡œ ì €ì¥ìš©)
    delta = timedelta(days=7)  # 7ì¼ ê°„ê²©

    while start <= end:
        chunk_start = start.strftime("%Y%m%d")
        chunk_end = min(start + delta - timedelta(days=1), end).strftime("%Y%m%d")

        print(f"ğŸ“… Fetching chunk: {chunk_start} ~ {chunk_end}")
        items = fetch_asos_daily(chunk_start, chunk_end, stn_id)

        if items:
            all_items.extend(items)
            filename = f"raw/asos_daily_{stn_id}_{chunk_start}_{chunk_end}.json"
            saved_files.append(filename)  # âœ… íŒŒì¼ ê²½ë¡œ ëˆ„ì  ì €ì¥

        time.sleep(2)
        start += delta

    # âœ… ë³‘í•© ë° ì¤‘ê°„íŒŒì¼ ì‚­ì œ
    if all_items:
        os.makedirs("raw", exist_ok=True)
        merged_path = f"raw/asos_daily_{stn_id}_{year}{month:02d}_full.json"

        with open(merged_path, "w", encoding="utf-8") as f:
            json.dump(all_items, f, ensure_ascii=False, indent=2)

        print(f"âœ… Merged {len(all_items)} records â†’ {merged_path}")

        # ğŸ§¹ ì£¼ê°„ íŒŒì¼ ìë™ ì‚­ì œ
        for fpath in saved_files:
            if os.path.exists(fpath):
                os.remove(fpath)
                print(f"ğŸ—‘ï¸ Removed intermediate file â†’ {fpath}")
            else:
                print(f"âš ï¸ Skipped (not found): {fpath}")
    else:
        print("âš ï¸ No data collected for the month.")

# --------------------------------------------------------------------
# âœ… 4ï¸âƒ£ ì‹¤í–‰ë¶€
# --------------------------------------------------------------------
if __name__ == "__main__":
    stn_id = "108"
    start_year = 2025
    start_month = 4

    # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í™•ì¸
    today = datetime.now()
    current_year = today.year
    current_month = today.month

    # ë¹„ì–´ìˆëŠ” ë‹¬ í™•ì¸ ë° ì‚¬ìš©ì ì…ë ¥
for year in range(start_year, current_year + 1):
    # í˜„ì¬ ì—°ë„ì¸ì§€ì— ë”°ë¼ 'ìµœëŒ€ ì›”'ì„ ë‹¤ë¥´ê²Œ ì„¤ì •
    if year < current_year:
        max_month = 12                 # ê³¼ê±° ì—°ë„ëŠ” 12ì›”ê¹Œì§€ ë‹¤ í™•ì¸
    else:
        max_month = current_month - 1  # í˜„ì¬ ì—°ë„ëŠ” 'ì§€ë‚œë‹¬'ê¹Œì§€ë§Œ í™•ì¸

    for month in range(start_month, max_month + 1):
        # ğŸ“Œ year == current_yearì¼ ë•Œ monthëŠ” 1 ~ (current_month-1) ë§Œ í¬í•¨ë¨
        last_month_file = f"raw/asos_daily_{stn_id}_{year}{month:02d}_full.json"

        if not os.path.exists(last_month_file):
            print(f"âš ï¸ {year}-{month:02d} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            user_input = input(
                f"{year}-{month:02d}ì˜ ë°ì´í„°ë¥¼ í˜¸ì¶œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/N): "
            ).strip().upper()
            if user_input == 'Y':
                fetch_asos_month_chunked(year=year, month=month, stn_id=stn_id)
        else:
            print(f"âœ… {year}-{month:02d} ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")

    # ë§ˆì§€ë§‰ìœ¼ë¡œ ì§€ë‚œë‹¬ ë°ì´í„° í˜¸ì¶œ
    last_month = today.month - 1 if today.month > 1 else 12
    last_year = today.year if today.month > 1 else today.year - 1
    last_month_file = f"raw/asos_daily_{stn_id}_{last_year}{last_month:02d}_full.json"

    if os.path.exists(last_month_file):
        print(f"ğŸ“… ì§€ë‚œë‹¬ ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {last_year}-{last_month:02d}.")
    else:
        print(f"ğŸ“… ì§€ë‚œë‹¬ ë°ì´í„° í˜¸ì¶œ ì¤‘: {last_year}-{last_month:02d}.")
        fetch_asos_month_chunked(year=last_year, month=last_month, stn_id=stn_id)